{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a8d0b8",
   "metadata": {},
   "source": [
    "# @alestamm Reddit coin data agreggator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaca3c",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5dfb77",
   "metadata": {},
   "source": [
    "Content agreggator that searchs Reddit for data on cryptocurrencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29263d",
   "metadata": {},
   "source": [
    "## Information gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e1e42",
   "metadata": {},
   "source": [
    "### Sites to look at:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20e5faf",
   "metadata": {},
   "source": [
    "Reddit activity: PushshiftAPI  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b0366",
   "metadata": {},
   "source": [
    "## Getting coin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacb68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import requests.auth\n",
    "from psaw import PushshiftAPI\n",
    "import json\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc55d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting coin data from CoinMarketCap API\n",
    "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "parameters = {\n",
    "  'start':'1',\n",
    "  'limit':'5000',\n",
    "  'convert':'USD'\n",
    "}\n",
    "headers = {\n",
    "  'Accepts': 'application/json',\n",
    "  'X-CMC_PRO_API_KEY': '091b2fdb-8206-4013-b957-d29f6804203f',\n",
    "}\n",
    "cmc_data = requests.get(url, params=parameters, headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a3d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Coins dataset\n",
    "coins = pd.json_normalize(cmc_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbd8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only useful columns\n",
    "coins.drop(columns=['id', 'num_market_pairs',\n",
    "       'tags', 'max_supply', 'self_reported_circulating_supply',\n",
    "       'self_reported_market_cap', 'last_updated',\n",
    "       'quote.USD.fully_diluted_market_cap', 'quote.USD.last_updated',\n",
    "       'platform.name', 'platform.symbol', 'platform.slug',\n",
    "       'platform.token_address', 'slug', 'platform.id', 'quote.USD.volume_change_24h', 'total_supply', 'platform'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export df to csv\n",
    "coins.to_csv('coins.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "100e2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset with top50 coins\n",
    "top_50 = coins.head(50).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e72256",
   "metadata": {},
   "source": [
    "## Get Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f22bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Def function to get crypto data from reddit submissions through reddit PushShift API\n",
    "\n",
    "def get_crypto_data(data_type, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Gets data from the pushshift api.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    base_url = f\"https://api.pushshift.io/reddit/search/{data_type}/\"\n",
    "    payload = kwargs\n",
    "    request = requests.get(base_url, params=payload)\n",
    "    reddit_data = request.json()\n",
    "    return reddit_data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3928031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty dict to store data\n",
    "subStats = {}\n",
    "\n",
    "#Def function to get useful information from crypto_data\n",
    "def collectSubData(subm):\n",
    "    \"\"\"\n",
    "    Get useful data from submission dictionary and store in subStats dict\n",
    "    \"\"\"\n",
    "    \n",
    "    subData = list() #list to store data points\n",
    "    name = f\"{coin_name}\"\n",
    "    title = subm['title']\n",
    "    url = subm['url']\n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"    \n",
    "    author = subm['author']\n",
    "    sub_id = subm['id']\n",
    "    score = subm['score']\n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
    "    numComms = subm['num_comments']\n",
    "    permalink = f\"https://www.reddit.com{subm['permalink']}\"\n",
    "    subData.append((name,title,permalink,numComms))\n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5d2f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through each coin in top_50 to get its data and append to 'subStats'\n",
    "data_type=\"submission\"\n",
    "size=50\n",
    "after = \"24h\"\n",
    "print(f\"Loop through each coin in top_50 to get {size} posts for each coin, this may take a while\")\n",
    "for coin_name in top_50['name']:\n",
    "    data = get_crypto_data(data_type=data_type,\n",
    "                          q=coin_name,\n",
    "                          size=size,\n",
    "                          after=after)\n",
    "    for i in range(0, len(data)):\n",
    "        collectSubData(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa311c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input filename of submission file, please add .csv\n",
      "teste.csv\n",
      "1478 submissions have been uploaded\n",
      "Program completed. Reddit data from top 50 coins wrote to teste.csv\n"
     ]
    }
   ],
   "source": [
    "# Write Data from coins into csv file\n",
    "def updateSubs_file():\n",
    "    \"\"\"\n",
    "    Write csv with Subs information\n",
    "    \"\"\"\n",
    "    upload_count = 0\n",
    "    print(\"input filename of submission file, please add .csv\")\n",
    "    filename = input()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file: \n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = ['Coin name','Title','Link','Number of comments']\n",
    "        a.writerow(headers)\n",
    "        for sub in subStats:\n",
    "            a.writerow(subStats[sub][0])\n",
    "            upload_count+=1\n",
    "            \n",
    "        print(str(upload_count) + \" submissions have been uploaded\")\n",
    "        print(f'Program completed. Reddit data from top 50 coins wrote to {filename}')\n",
    "updateSubs_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
